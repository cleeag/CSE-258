{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1143860\n",
      "{'overall': 5.0, 'verified': True, 'reviewTime': '11 19, 2014', 'reviewerID': 'A1QVBUH9E1V6I8', 'asin': '4639725183', 'reviewerName': 'Jamshed Mathur', 'reviewText': 'No adverse comment.', 'summary': 'Five Stars', 'unixReviewTime': 1416355200}\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with gzip.open('data\\Grocery_and_Gourmet_Food_5.json.gz') as f:\n",
    "    for l in f:\n",
    "        data.append(json.loads(l.strip()))\n",
    "    \n",
    "# total length of list, this number equals total number of products\n",
    "print(len(data))\n",
    "\n",
    "# first row of the list\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_vals=['overall','verified','reviewTime','reviewerID','asin','reviewText','summary','unixReviewTime']\n",
    "data_cleaned=[]\n",
    "cnt==0\n",
    "imgcnt=0\n",
    "for d in data: \n",
    "    add=True \n",
    "    for i in required_vals:\n",
    "        if i not in d:\n",
    "            add=False \n",
    "    if add:\n",
    "        dcopy=copy.deepcopy(d) #not sure if this is really needed, will most likely remove\n",
    "        if 'image' in dcopy:\n",
    "            imgcnt+=1\n",
    "            dcopy['hasImage']=1\n",
    "        else:\n",
    "            dcopy['hasImage']=0\n",
    "        data_cleaned.append(dcopy)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgcnt)\n",
    "#this is  small so the image feature might be useless "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle dataset\n",
    "random.shuffle(data_cleaned)\n",
    "train_data=data_cleaned[:int((len(data_cleaned)+1)*.80)]\n",
    "val_data=data_cleaned[int((len(data_cleaned)+1)*.80):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=[]\n",
    "test_set=[]\n",
    "cnt=0\n",
    "\n",
    "itemsPerUser=defaultdict(set)\n",
    "usersPerItem=defaultdict(set)\n",
    "items=set()\n",
    "itemCount=defaultdict(int) # keep track of total times an item is reviewed\n",
    "\n",
    "for review in train_data:\n",
    "    user=review['reviewerID']\n",
    "    item=review['asin']\n",
    "    itemsPerUser[user].add(item)\n",
    "    usersPerItem[item].add(user)\n",
    "    items.add(item)\n",
    "    itemCount[item]+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See \"simple bias only latent factor model\"\n",
    "https://cseweb.ucsd.edu//classes/fa20/cse258-a/code/workbook4.html\n",
    "\n",
    "This is a basic latent factor model from prev assignment (needs to be improved). Uses information only from user item pairs and ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.442731190836991"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels= [int(d['overall']) for d in train_data]\n",
    "ratingMean = sum([int(d['overall']) for d in train_data]) / len(train_data)\n",
    "ratingMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences = collections.Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = len(train_set)\n",
    "nUsers = len(itemsPerUser)\n",
    "nItems = len(usersPerItem)\n",
    "users = list(itemsPerUser.keys())\n",
    "items = list(usersPerItem.keys())\n",
    "alpha = ratingMean\n",
    "\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]\n",
    "\n",
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)\n",
    "\n",
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n",
    "    \n",
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in train_set]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost\n",
    "\n",
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(train_set)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in train_set:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - int(d[2])\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.1303754596136466\n",
      "MSE = 1.427133374754615\n",
      "MSE = 1.1302913946672712\n",
      "MSE = 1.1301753083736292\n",
      "MSE = 1.1297151629412159\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#basic  latent factor model from prev assignment (needs to be improved)\n",
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, .001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e3abd38b0175449e66dcb706d52ad9e71dd92443e43314c772b1f826141991c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
